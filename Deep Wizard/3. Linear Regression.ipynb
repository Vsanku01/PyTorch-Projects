{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple Linear Regression Basics\n",
    "Allows us to understand relationship between two continuous variables\n",
    "* Example\n",
    "  * x: independent variable\n",
    "    * weight\n",
    "  * y: dependent variable\n",
    "    * height\n",
    "* y = \\alpha x + \\beta\n",
    "\n",
    "\n",
    "\n",
    "Aim of Linear Regression\n",
    "* Minimize the distance between the points and the line (y = \\alpha x + \\beta)\n",
    "* Adjusting\n",
    "    * Coefficient: \\alpha\n",
    "    * Bias/intercept: \\beta\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression Model with Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n"
     ]
    }
   ],
   "source": [
    "x_values = [i for i in range(11)]\n",
    "print(x_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11,)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = np.array(x_values,dtype=np.float32)\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#If you don't this you will get an error stating you need 2D. Simply just reshape accordingly if you ever face such errors down the road.\n",
    "\n",
    "\n",
    "# IMPORTANT: 2D required\n",
    "x_train = x_train.reshape(-1, 1)\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Suppose function is y = 2x +1\n",
    "\n",
    "y_values = [2*i for i in x_values]\n",
    "y_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_values = []\n",
    "# for i in x_values:\n",
    "#     result = 2*i + 1\n",
    "#     y_values.append(result)\n",
    "# y_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = np.array(y_values,dtype=np.float32)\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = y_train.reshape(-1,1)\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Linear model\n",
    "   * True Equation: y = 2x + 1\n",
    "2. Forward\n",
    "  * Example\n",
    "Input x = 1,\n",
    "Output \\hat y = ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create class\n",
    "class LinearRegressionModel(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(LinearRegressionModel, self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, output_dim)  \n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 1\n",
    "output_dim = 1\n",
    "\n",
    "model = LinearRegressionModel(input_dim,output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "learning_rate = 0.01\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1,loss193.30284118652344\n",
      "epoch 2,loss15.911920547485352\n",
      "epoch 3,loss1.441087245941162\n",
      "epoch 4,loss0.25914672017097473\n",
      "epoch 5,loss0.16115888953208923\n",
      "epoch 6,loss0.1516026258468628\n",
      "epoch 7,loss0.14927707612514496\n",
      "epoch 8,loss0.14755846560001373\n",
      "epoch 9,loss0.14590658247470856\n",
      "epoch 10,loss0.14427681267261505\n",
      "epoch 11,loss0.14266586303710938\n",
      "epoch 12,loss0.14107254147529602\n",
      "epoch 13,loss0.1394972950220108\n",
      "epoch 14,loss0.13793963193893433\n",
      "epoch 15,loss0.13639910519123077\n",
      "epoch 16,loss0.13487601280212402\n",
      "epoch 17,loss0.13336989283561707\n",
      "epoch 18,loss0.1318807303905487\n",
      "epoch 19,loss0.13040791451931\n",
      "epoch 20,loss0.1289515644311905\n",
      "epoch 21,loss0.12751160562038422\n",
      "epoch 22,loss0.12608781456947327\n",
      "epoch 23,loss0.12467977404594421\n",
      "epoch 24,loss0.12328753620386124\n",
      "epoch 25,loss0.12191072106361389\n",
      "epoch 26,loss0.12054936587810516\n",
      "epoch 27,loss0.11920326203107834\n",
      "epoch 28,loss0.11787211149930954\n",
      "epoch 29,loss0.11655572056770325\n",
      "epoch 30,loss0.11525421589612961\n",
      "epoch 31,loss0.11396720260381699\n",
      "epoch 32,loss0.1126946210861206\n",
      "epoch 33,loss0.11143619567155838\n",
      "epoch 34,loss0.11019176989793777\n",
      "epoch 35,loss0.108961321413517\n",
      "epoch 36,loss0.1077444776892662\n",
      "epoch 37,loss0.10654139518737793\n",
      "epoch 38,loss0.1053515374660492\n",
      "epoch 39,loss0.10417518764734268\n",
      "epoch 40,loss0.103011853992939\n",
      "epoch 41,loss0.10186168551445007\n",
      "epoch 42,loss0.10072402656078339\n",
      "epoch 43,loss0.09959927201271057\n",
      "epoch 44,loss0.09848704934120178\n",
      "epoch 45,loss0.09738744050264359\n",
      "epoch 46,loss0.09629974514245987\n",
      "epoch 47,loss0.09522441029548645\n",
      "epoch 48,loss0.09416107833385468\n",
      "epoch 49,loss0.09310965240001678\n",
      "epoch 50,loss0.09206988662481308\n",
      "epoch 51,loss0.09104171395301819\n",
      "epoch 52,loss0.09002509713172913\n",
      "epoch 53,loss0.08901988714933395\n",
      "epoch 54,loss0.08802580833435059\n",
      "epoch 55,loss0.0870426818728447\n",
      "epoch 56,loss0.0860707089304924\n",
      "epoch 57,loss0.0851096510887146\n",
      "epoch 58,loss0.08415932208299637\n",
      "epoch 59,loss0.08321947604417801\n",
      "epoch 60,loss0.08229012042284012\n",
      "epoch 61,loss0.0813712328672409\n",
      "epoch 62,loss0.08046259731054306\n",
      "epoch 63,loss0.07956403493881226\n",
      "epoch 64,loss0.07867555320262909\n",
      "epoch 65,loss0.07779712975025177\n",
      "epoch 66,loss0.07692822068929672\n",
      "epoch 67,loss0.076069176197052\n",
      "epoch 68,loss0.07521979510784149\n",
      "epoch 69,loss0.07437973469495773\n",
      "epoch 70,loss0.07354926317930222\n",
      "epoch 71,loss0.07272790372371674\n",
      "epoch 72,loss0.07191581279039383\n",
      "epoch 73,loss0.07111270725727081\n",
      "epoch 74,loss0.07031861692667007\n",
      "epoch 75,loss0.06953339278697968\n",
      "epoch 76,loss0.06875688582658768\n",
      "epoch 77,loss0.06798912584781647\n",
      "epoch 78,loss0.06722988933324814\n",
      "epoch 79,loss0.06647918373346329\n",
      "epoch 80,loss0.0657368004322052\n",
      "epoch 81,loss0.06500276923179626\n",
      "epoch 82,loss0.0642768144607544\n",
      "epoch 83,loss0.06355898082256317\n",
      "epoch 84,loss0.06284921616315842\n",
      "epoch 85,loss0.062147464603185654\n",
      "epoch 86,loss0.06145347282290459\n",
      "epoch 87,loss0.06076713651418686\n",
      "epoch 88,loss0.06008864939212799\n",
      "epoch 89,loss0.059417594224214554\n",
      "epoch 90,loss0.058754172176122665\n",
      "epoch 91,loss0.05809807777404785\n",
      "epoch 92,loss0.05744931846857071\n",
      "epoch 93,loss0.05680780112743378\n",
      "epoch 94,loss0.05617348104715347\n",
      "epoch 95,loss0.05554612725973129\n",
      "epoch 96,loss0.05492578446865082\n",
      "epoch 97,loss0.05431240424513817\n",
      "epoch 98,loss0.053705934435129166\n",
      "epoch 99,loss0.05310628190636635\n",
      "epoch 100,loss0.052513156086206436\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "for epoch in range(epochs):\n",
    "    epoch += 1\n",
    "    # Convert numpy to tensors\n",
    "    inputs = torch.from_numpy(x_train).requires_grad_()\n",
    "    labels = torch.from_numpy(y_train)\n",
    "    \n",
    "    # Clear gradient w.r.t paramters\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Forward to get output\n",
    "    outputs = model(inputs)\n",
    "    \n",
    "    # Calc Loss\n",
    "    loss = criterion(outputs,labels)\n",
    "    #Getting gradients w.r.t parameters\n",
    "    loss.backward()\n",
    "    \n",
    "    #Update paramters\n",
    "    optimizer.step()\n",
    "    \n",
    "    print('epoch {},loss{}'.format(epoch,loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.4262797],\n",
       "       [ 2.3648915],\n",
       "       [ 4.3035035],\n",
       "       [ 6.242115 ],\n",
       "       [ 8.180727 ],\n",
       "       [10.119339 ],\n",
       "       [12.057951 ],\n",
       "       [13.996563 ],\n",
       "       [15.935175 ],\n",
       "       [17.873785 ],\n",
       "       [19.812397 ]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Purely inference\n",
    "predicted = model(torch.from_numpy(x_train).requires_grad_()).data.numpy()\n",
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.],\n",
       "       [ 2.],\n",
       "       [ 4.],\n",
       "       [ 6.],\n",
       "       [ 8.],\n",
       "       [10.],\n",
       "       [12.],\n",
       "       [14.],\n",
       "       [16.],\n",
       "       [18.],\n",
       "       [20.]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y = 2x + 1 \n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Clear figure\n",
    "plt.clf()\n",
    "\n",
    "# Get predictions\n",
    "predicted = model(torch.from_numpy(x_train).requires_grad_()).data.numpy()\n",
    "\n",
    "# Plot true data\n",
    "plt.plot(x_train, y_train, 'go', label='True data', alpha=0.5)\n",
    "\n",
    "# Plot predictions\n",
    "plt.plot(x_train, predicted, '--', label='Predictions', alpha=0.5)\n",
    "\n",
    "# Legend and plot\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model = False\n",
    "if save_model is True:\n",
    "    # Saves only parameters\n",
    "    # alpha & beta\n",
    "    torch.save(model.state_dict(), 'awesome_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model = False\n",
    "if load_model is True:\n",
    "    model.load_state_dict(torch.load('awesome_model.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU Version\n",
    "\n",
    "* Just remember always 2 things must be on GPU\n",
    "    * model\n",
    "    * tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 69.49633026123047\n",
      "epoch 2, loss 5.696641445159912\n",
      "epoch 3, loss 0.49239107966423035\n",
      "epoch 4, loss 0.06758671253919601\n",
      "epoch 5, loss 0.03263082727789879\n",
      "epoch 6, loss 0.02947675995528698\n",
      "epoch 7, loss 0.028920035809278488\n",
      "epoch 8, loss 0.0285784974694252\n",
      "epoch 9, loss 0.028257863596081734\n",
      "epoch 10, loss 0.027942122891545296\n",
      "epoch 11, loss 0.0276301521807909\n",
      "epoch 12, loss 0.027321545407176018\n",
      "epoch 13, loss 0.02701651304960251\n",
      "epoch 14, loss 0.026714831590652466\n",
      "epoch 15, loss 0.026416487991809845\n",
      "epoch 16, loss 0.02612154372036457\n",
      "epoch 17, loss 0.025829775258898735\n",
      "epoch 18, loss 0.025541378185153008\n",
      "epoch 19, loss 0.02525620348751545\n",
      "epoch 20, loss 0.024974102154374123\n",
      "epoch 21, loss 0.02469526417553425\n",
      "epoch 22, loss 0.02441946417093277\n",
      "epoch 23, loss 0.02414676547050476\n",
      "epoch 24, loss 0.023877225816249847\n",
      "epoch 25, loss 0.023610495030879974\n",
      "epoch 26, loss 0.02334686368703842\n",
      "epoch 27, loss 0.023086143657565117\n",
      "epoch 28, loss 0.022828297689557076\n",
      "epoch 29, loss 0.022573433816432953\n",
      "epoch 30, loss 0.022321371361613274\n",
      "epoch 31, loss 0.022072143852710724\n",
      "epoch 32, loss 0.021825561299920082\n",
      "epoch 33, loss 0.021581942215561867\n",
      "epoch 34, loss 0.021340833976864815\n",
      "epoch 35, loss 0.02110261283814907\n",
      "epoch 36, loss 0.02086692862212658\n",
      "epoch 37, loss 0.02063394896686077\n",
      "epoch 38, loss 0.020403489470481873\n",
      "epoch 39, loss 0.020175686106085777\n",
      "epoch 40, loss 0.01995038241147995\n",
      "epoch 41, loss 0.01972765102982521\n",
      "epoch 42, loss 0.01950732059776783\n",
      "epoch 43, loss 0.019289476796984673\n",
      "epoch 44, loss 0.019074084237217903\n",
      "epoch 45, loss 0.01886102743446827\n",
      "epoch 46, loss 0.018650434911251068\n",
      "epoch 47, loss 0.018442166969180107\n",
      "epoch 48, loss 0.018236225470900536\n",
      "epoch 49, loss 0.018032534047961235\n",
      "epoch 50, loss 0.017831245437264442\n",
      "epoch 51, loss 0.017632124945521355\n",
      "epoch 52, loss 0.017435209825634956\n",
      "epoch 53, loss 0.017240451648831367\n",
      "epoch 54, loss 0.01704796962440014\n",
      "epoch 55, loss 0.016857566311955452\n",
      "epoch 56, loss 0.016669346019625664\n",
      "epoch 57, loss 0.01648319512605667\n",
      "epoch 58, loss 0.016299141570925713\n",
      "epoch 59, loss 0.01611720770597458\n",
      "epoch 60, loss 0.015937183052301407\n",
      "epoch 61, loss 0.015759194269776344\n",
      "epoch 62, loss 0.015583205036818981\n",
      "epoch 63, loss 0.015409239567816257\n",
      "epoch 64, loss 0.015237163752317429\n",
      "epoch 65, loss 0.015066959895193577\n",
      "epoch 66, loss 0.014898714609444141\n",
      "epoch 67, loss 0.014732390642166138\n",
      "epoch 68, loss 0.01456783339381218\n",
      "epoch 69, loss 0.014405196532607079\n",
      "epoch 70, loss 0.014244304038584232\n",
      "epoch 71, loss 0.014085284434258938\n",
      "epoch 72, loss 0.013927960768342018\n",
      "epoch 73, loss 0.013772415928542614\n",
      "epoch 74, loss 0.01361864898353815\n",
      "epoch 75, loss 0.01346656959503889\n",
      "epoch 76, loss 0.013316166587173939\n",
      "epoch 77, loss 0.01316749770194292\n",
      "epoch 78, loss 0.013020447455346584\n",
      "epoch 79, loss 0.012875008396804333\n",
      "epoch 80, loss 0.012731230817735195\n",
      "epoch 81, loss 0.012589111924171448\n",
      "epoch 82, loss 0.012448507361114025\n",
      "epoch 83, loss 0.012309515848755836\n",
      "epoch 84, loss 0.012172036804258823\n",
      "epoch 85, loss 0.012036138214170933\n",
      "epoch 86, loss 0.011901700869202614\n",
      "epoch 87, loss 0.011768861673772335\n",
      "epoch 88, loss 0.011637374758720398\n",
      "epoch 89, loss 0.011507454328238964\n",
      "epoch 90, loss 0.01137896254658699\n",
      "epoch 91, loss 0.011251911520957947\n",
      "epoch 92, loss 0.011126216500997543\n",
      "epoch 93, loss 0.011001977138221264\n",
      "epoch 94, loss 0.010879120789468288\n",
      "epoch 95, loss 0.010757618583738804\n",
      "epoch 96, loss 0.010637513361871243\n",
      "epoch 97, loss 0.010518738999962807\n",
      "epoch 98, loss 0.01040123775601387\n",
      "epoch 99, loss 0.010285093449056149\n",
      "epoch 100, loss 0.010170254856348038\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "'''\n",
    "STEP 1: CREATE MODEL CLASS\n",
    "'''\n",
    "class LinearRegressionModel(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(LinearRegressionModel, self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, output_dim)  \n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        return out\n",
    "\n",
    "'''\n",
    "STEP 2: INSTANTIATE MODEL CLASS\n",
    "'''\n",
    "input_dim = 1\n",
    "output_dim = 1\n",
    "\n",
    "model = LinearRegressionModel(input_dim, output_dim)\n",
    "\n",
    "\n",
    "#######################\n",
    "#  USE GPU FOR MODEL  #\n",
    "#######################\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "'''\n",
    "STEP 3: INSTANTIATE LOSS CLASS\n",
    "'''\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "'''\n",
    "STEP 4: INSTANTIATE OPTIMIZER CLASS\n",
    "'''\n",
    "\n",
    "learning_rate = 0.01\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "'''\n",
    "STEP 5: TRAIN THE MODEL\n",
    "'''\n",
    "epochs = 100\n",
    "for epoch in range(epochs):\n",
    "    epoch += 1\n",
    "    # Convert numpy array to torch Variable\n",
    "\n",
    "    #######################\n",
    "    #  USE GPU FOR MODEL  #\n",
    "    #######################\n",
    "    inputs = torch.from_numpy(x_train).to(device)\n",
    "    labels = torch.from_numpy(y_train).to(device)\n",
    "\n",
    "    # Clear gradients w.r.t. parameters\n",
    "    optimizer.zero_grad() \n",
    "\n",
    "    # Forward to get output\n",
    "    outputs = model(inputs)\n",
    "\n",
    "    # Calculate Loss\n",
    "    loss = criterion(outputs, labels)\n",
    "\n",
    "    # Getting gradients w.r.t. parameters\n",
    "    loss.backward()\n",
    "\n",
    "    # Updating parameters\n",
    "    optimizer.step()\n",
    "\n",
    "    # Logging\n",
    "    print('epoch {}, loss {}'.format(epoch, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
